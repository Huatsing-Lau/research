{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Classification\n",
    "updated: Sep. 01, 2018\n",
    "\n",
    "Data: https://www.physionet.org/pn4/eegmmidb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Downloads\n",
    "\n",
    "### Warning: Executing these blocks will automatically create directories and download datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import urllib\n",
    "\n",
    "# Modeling & Preprocessing\n",
    "from keras.layers import Conv2D, Dense, TimeDistributed, Dropout, Flatten, Activation, BatchNormalization, LSTM\n",
    "from keras.models import Sequential, model_from_json, Model\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from keras import initializers, optimizers, callbacks, models\n",
    "\n",
    "# Essential Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get Paths\n",
    "from glob import glob\n",
    "\n",
    "# EEG package\n",
    "from mne import find_events, Epochs, concatenate_raws, pick_types\n",
    "from mne.channels import read_montage\n",
    "from mne.io import read_raw_edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = 'pn4/'\n",
    "MATERIAL = 'eegmmidb/'\n",
    "URL = 'https://www.physionet.org/' + CONTEXT + MATERIAL\n",
    "\n",
    "# Change this directory according to your setting\n",
    "USERDIR = '/Users/Jimmy/data/PhysioNet/'\n",
    "\n",
    "page = requests.get(URL).text\n",
    "FOLDERS = sorted(list(set(re.findall(r'S[0-9]+', page))))\n",
    "\n",
    "URLS = [URL+x+'/' for x in FOLDERS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Executing this block will create folders\n",
    "for folder in FOLDERS:\n",
    "    pathlib.Path(USERDIR +'/'+ folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Executing this block will start downloading data\n",
    "for i, folder in enumerate(FOLDERS):\n",
    "    page = requests.get(URLS[i]).text\n",
    "    subs = list(set(re.findall(r'S[0-9]+R[0-9]+', page)))\n",
    "    \n",
    "    print('Working on {}, {:.1%} completed'.format(folder, (i+1)/len(FOLDERS)))\n",
    "    for sub in subs:\n",
    "        urllib.request.urlretrieve(URLS[i]+sub+'.edf', os.path.join(USERDIR, folder, sub+'.edf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Subjects performed different motor/imagery tasks while 64-channel EEG were recorded using the BCI2000 system (http://www.bci2000.org). Each subject performed 14 experimental runs: two one-minute baseline runs (one with eyes open, one with eyes closed), and three two-minute runs of each of the four following tasks:\n",
    "A target appears on either the left or the right side of the screen. The subject opens and closes the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "A target appears on either the left or the right side of the screen. The subject imagines opening and closing the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "A target appears on either the top or the bottom of the screen. The subject opens and closes either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "A target appears on either the top or the bottom of the screen. The subject imagines opening and closing either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "\n",
    "The data are provided here in EDF+ format (containing 64 EEG signals, each sampled at 160 samples per second, and an annotation channel). For use with PhysioToolkit software, rdedfann generated a separate PhysioBank-compatible annotation file (with the suffix .event) for each recording. The .event files and the annotation channels in the corresponding .edf files contain identical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Raw Data Import\n",
    "\n",
    "I will use a EEG data handling package named MNE (https://martinos.org/mne/stable/index.html) to import raw data and annotation for events from edf files. This package also provides essential signal analysis features, e.g. band-pass filtering. The raw data were filtered using 1Hz of high-pass filter.\n",
    "\n",
    "In this research, there are 5 classes for the data: imagined motion of right fist, left fist, both fists, both feet, and rest with eyes closed. A data from one of the 109 subjects was excluded as the record was severely corrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths\n",
    "PATH = '/Users/jimmy/data/PhysioNet/'\n",
    "SUBS = glob(PATH + 'S[0-9]*')\n",
    "FNAMES = sorted([x[-4:] for x in SUBS])\n",
    "\n",
    "# Remove subject #89 with damaged data\n",
    "FNAMES.remove('S089')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subj_num=FNAMES, epoch_sec=0.0625):\n",
    "    \"\"\" Import each subject`s trials and make a 3D array\n",
    "        Output shape: (Trial*Channel*TimeFrames)\n",
    "        \n",
    "        Some edf+ files recorded at low sampling rate, 128Hz, are excluded. \n",
    "        Majority was sampled at 160Hz.\n",
    "        \n",
    "        epoch_sec: time interval for one segment of mashes\n",
    "        \"\"\"\n",
    "    \n",
    "    # Event codes mean different actions for two groups of runs\n",
    "    run_type_0 = '02'.split(',')\n",
    "    run_type_1 = '04,08,12'.split(',')\n",
    "    run_type_2 = '06,10,14'.split(',')\n",
    "\n",
    "    # To calculated completion rate\n",
    "    count = 0\n",
    "    \n",
    "    # Initiate X, y\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # fixed numbers\n",
    "    nChan = 64 \n",
    "    sfreq = 160\n",
    "    sliding = epoch_sec/2 \n",
    "    \n",
    "    # Sub-function to assign X and X, y\n",
    "    def append_X(n_segments, old_x):\n",
    "        new_x = old_x + [data[:, int(sfreq*sliding*n):int(sfreq*sliding*(n+2))] for n in range(n_segments)\\\n",
    "                     if data[:, int(sfreq*sliding*n):int(sfreq*sliding*(n+2))].shape==(nChan, int(sfreq*epoch_sec))]\n",
    "        return new_x\n",
    "    \n",
    "    def append_X_Y(run_type, event, old_x, old_y):\n",
    "        # Number of sliding windows\n",
    "        n_segments = int(event[1]/epoch_sec)*2-1\n",
    "        \n",
    "        # Instantiate new_x, new_y\n",
    "        new_y = old_y\n",
    "        new_x = old_x\n",
    "        \n",
    "        # y assignment\n",
    "        if run_type == 1:\n",
    "            if event[2] == 'T1':\n",
    "                new_y = old_y + [1]*n_segments\n",
    "                new_x = append_X(n_segments, old_x)\n",
    "\n",
    "            elif event[2] == 'T2':\n",
    "                new_y = old_y + [2]*n_segments\n",
    "                new_x = append_X(n_segments, old_x)\n",
    "        \n",
    "        if run_type == 2:\n",
    "            if event[2] == 'T1':\n",
    "                new_y = old_y + [3]*n_segments\n",
    "                new_x = append_X(n_segments, old_x)\n",
    "            \n",
    "            elif event[2] == 'T2':\n",
    "                new_y = old_y + [4]*n_segments\n",
    "                new_x = append_X(n_segments, old_x)\n",
    "        \n",
    "        return new_x, new_y\n",
    "    \n",
    "    # Iterate over subj_num: S001, S002, S003...\n",
    "    for subj in subj_num:\n",
    "        # Return completion rate\n",
    "        count+=1\n",
    "        if len(subj_num)//count == 10:\n",
    "            print('working on {}, {:.1%} completed'.format(subj, count/len(subj_num)))\n",
    "\n",
    "        # Get file names\n",
    "        fnames = glob(os.path.join(PATH, subj, subj+'R*.edf'))\n",
    "        fnames = [name for name in fnames if name[-6:-4] in run_type_0+run_type_1+run_type_2]\n",
    "        \n",
    "        for i, fname in enumerate(fnames):\n",
    "            \n",
    "            # Import data into MNE raw object\n",
    "            raw = read_raw_edf(fname, preload=True, verbose=False)\n",
    "            picks = pick_types(raw.info, eeg=True)\n",
    "            \n",
    "            if raw.info['sfreq'] != 160:\n",
    "                print(f'{subj} is sampled at 128Hz so will be excluded.')\n",
    "                break\n",
    "            \n",
    "            # High-pass filtering\n",
    "            raw.filter(l_freq=1, h_freq=None, picks=picks)\n",
    "            \n",
    "            # Get annotation\n",
    "            events = raw.find_edf_events()\n",
    "            \n",
    "            # Get data\n",
    "            data = raw.get_data(picks=picks)\n",
    "            \n",
    "            # Number of this run\n",
    "            which_run = fname[-6:-4]\n",
    "            \n",
    "            \"\"\" Assignment Starts \"\"\" \n",
    "            # run 1 - baseline (eye closed)\n",
    "            if which_run in run_type_0:\n",
    "\n",
    "                # Number of sliding windows\n",
    "                n_segments = int((raw.n_times/(epoch_sec*sfreq))*2-1)\n",
    "                \n",
    "                # Append 0`s based on number of windows\n",
    "                y.extend([0]*n_segments)\n",
    "                X = append_X(n_segments, X)\n",
    "                    \n",
    "            # run 4,8,12 - imagine opening and closing left or right fist    \n",
    "            elif which_run in run_type_1:\n",
    "                \n",
    "                for i, event in enumerate(events):\n",
    "                    X, y = append_X_Y(run_type=1, event=event, old_x=X, old_y=y)\n",
    "                        \n",
    "            # run 6,10,14 - imagine opening and closing both fists or both feet\n",
    "            elif which_run in run_type_2:\n",
    "                   \n",
    "                for i, event in enumerate(events):         \n",
    "                    X, y = append_X_Y(run_type=2, event=event, old_x=X, old_y=y)\n",
    "                        \n",
    "    X = np.stack(X)\n",
    "    y = np.array(y).reshape((-1,1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This code is to test MNE raw object\n",
    "\n",
    "subj = FNAMES[0]\n",
    "fnames = glob(os.path.join(PATH, subj, subj+'R*'+'.edf'))\n",
    "raw = read_raw_edf(fnames[5], preload=True, verbose=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on S010, 9.3% completed\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d4bb9110f138>:76: RuntimeWarning: EDF+ with overlapping events are not fully supported\n",
      "  raw = read_raw_edf(fname, preload=True, verbose=False)\n",
      "<ipython-input-4-d4bb9110f138>:76: RuntimeWarning: EDF+ with overlapping events are not fully supported\n",
      "  raw = read_raw_edf(fname, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S088 is sampled at 128Hz so will be excluded.\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d4bb9110f138>:76: RuntimeWarning: EDF+ with overlapping events are not fully supported\n",
      "  raw = read_raw_edf(fname, preload=True, verbose=False)\n",
      "<ipython-input-4-d4bb9110f138>:76: RuntimeWarning: EDF+ with overlapping events are not fully supported\n",
      "  raw = read_raw_edf(fname, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S092 is sampled at 128Hz so will be excluded.\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-4-d4bb9110f138>:76: RuntimeWarning: EDF+ with overlapping events are not fully supported\n",
      "  raw = read_raw_edf(fname, preload=True, verbose=False)\n",
      "<ipython-input-4-d4bb9110f138>:76: RuntimeWarning: EDF+ with overlapping events are not fully supported\n",
      "  raw = read_raw_edf(fname, preload=True, verbose=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S100 is sampled at 128Hz so will be excluded.\n"
     ]
    }
   ],
   "source": [
    "X,y = get_data(FNAMES, epoch_sec=0.0625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1425410, 64, 10)\n",
      "(1425410, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "The original goal of applying neural networks is to exclude hand-crafted algorithms & preprocessing as much as possible. I did not use any proprecessing techniques further than standardization to build an end-to-end classifer from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y backup\n",
    "ori_y = y\n",
    "\n",
    "# y encoding\n",
    "oh = OneHotEncoder()\n",
    "y = oh.fit_transform(ori_y).toarray()\n",
    "\n",
    "# Shuffle trials\n",
    "np.random.seed(43)\n",
    "trials = X.shape[0]\n",
    "shuffle_indices = np.random.permutation(trials)\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Test set seperation\n",
    "test_ratio = 0.2\n",
    "train_size = int(trials*(1-test_ratio))\n",
    "X_train, X_test, y_train, y_test = X[:train_size,:,:], X[train_size:,:,:],\\\n",
    "                                    y[:train_size,:], y[train_size:,:]\n",
    "    \n",
    "# Z-score Normalization\n",
    "def scale_data(X):\n",
    "    shape = X.shape\n",
    "    scaler = StandardScaler()\n",
    "    scaled_X = np.zeros((shape[0], shape[1], shape[2]))\n",
    "    for i in range(shape[0]):\n",
    "        for z in range(shape[2]):\n",
    "            scaled_X[i, :, z] = np.squeeze(scaler.fit_transform(X[i, :, z].reshape(-1, 1)))\n",
    "        if i%int(shape[0]/10) == 0:\n",
    "            print('{:.2%} done'.format((i+1)/shape[0]))   \n",
    "    return scaled_X\n",
    "            \n",
    "X_train, X_test  = scale_data(X_train), scale_data(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the EEG recording instrument has 3D locations over the subjects\\` scalp, it is essential for the model to learn from the spatial pattern as well as the temporal pattern. I transformed the data into 2D meshes that represents the locations of the electrodes so that stacked convolutional neural networks can grasp the spatial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Make 2D meshes\n",
    "# Import one raw EEG data to get electrode locations\n",
    "subj = FNAMES[0]\n",
    "fnames = glob(os.path.join(PATH, subj, subj+'R*'+'.edf'))\n",
    "raw = read_raw_edf(fnames[3], preload=True, verbose=False)\n",
    "ch_names = raw.info['ch_names'][:-1]\n",
    "\n",
    "# 'ch_index' is a dictionary - keys: electrodes, vals: column index of electrodes\n",
    "ch_index = {re.findall(\"\\w+[0-9]?\", i)[0]:ch_names.index(i) for i in ch_names}; ch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mesh(X, ch_index=ch_index):\n",
    "    \n",
    "    mesh = np.zeros((X.shape[0], X.shape[2], 10, 11))\n",
    "    X = np.swapaxes(X, 1, 2)\n",
    "    \n",
    "    # 1st line\n",
    "    mesh[:, :, 0, 4:7] = X[:,:,21:24]; print('1st finished')\n",
    "    \n",
    "    # 2nd line\n",
    "    mesh[:, :, 1, 3:8] = X[:,:,24:29]; print('2nd finished')\n",
    "    \n",
    "    # 3rd line\n",
    "    mesh[:, :, 2, 1:10] = X[:,:,29:38]; print('3rd finished')\n",
    "    \n",
    "    # 4th line\n",
    "    mesh[:, :, 3, 1:10] = np.concatenate((X[:,:,ch_index['Ft7']].reshape(-1, X.shape[1], 1),\\\n",
    "                                          X[:,:,0:7], X[:,:,ch_index['Ft8']].reshape(-1, X.shape[1], 1)), axis=2)\n",
    "    print('4th finished')\n",
    "    \n",
    "    # 5th line\n",
    "    mesh[:, :, 4, 0:11] = np.concatenate((X[:,:,(ch_index['T9'],ch_index['T7'])],\\\n",
    "                                        X[:,:,7:14], X[:,:,(ch_index['T8'],ch_index['T10'])]), axis=2)\n",
    "    print('5th finished')\n",
    "    \n",
    "    # 6th line\n",
    "    mesh[:, :, 5, 1:10] = np.concatenate((X[:,:,ch_index['Tp7']].reshape(-1, X.shape[1], 1),\\\n",
    "                                        X[:,:,14:21], X[:,:,ch_index['Tp8']].reshape(-1, X.shape[1], 1)), axis=2)\n",
    "    print('6th finished')\n",
    "               \n",
    "    # 7th line\n",
    "    mesh[:, :, 6, 1:10] = X[:,:,46:55]; print('7th finished')\n",
    "    \n",
    "    # 8th line\n",
    "    mesh[:, :, 7, 3:8] = X[:,:,55:60]; print('8th finished')\n",
    "    \n",
    "    # 9th line\n",
    "    mesh[:, :, 8, 4:7] = X[:,:,60:63]; print('9th finished')\n",
    "    \n",
    "    # 10th line\n",
    "    mesh[:, :, 9, 5] = X[:,:,63]; print('10th finished')\n",
    "    \n",
    "    return mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make meshes - Dimension: (Sample * Channel * Width * Height)\n",
    "X_train, X_test = convert_mesh(X_train), convert_mesh(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check out the shape of the mesh\n",
    "np.set_printoptions(precision=2, linewidth=100)\n",
    "X_train[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling - Time-Distributed CNN + RNN\n",
    "\n",
    "Training Plan:\n",
    "\n",
    "+ 4 GPU units (Nvidia Tesla P100) were used to train this neural network.\n",
    "+ Instead of training the whole model at once, I trained the first block (CNN) first. Then using the trained parameters as initial values, I trained the next blocks step-by-step. This approach can greatly reduce the time required for training and help avoiding falling into local minimums.\n",
    "+ The first blocks (CNN) can be applied for other EEG classification models as a pre-trained base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make another dimension, 1, to apply CNN for each time frame.\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_12 (InputLayer)        (None, 10, 10, 11, 1)     0         \n",
      "_________________________________________________________________\n",
      "CNN1 (TimeDistributed)       (None, 10, 10, 11, 32)    320       \n",
      "_________________________________________________________________\n",
      "batch1 (BatchNormalization)  (None, 10, 10, 11, 32)    128       \n",
      "_________________________________________________________________\n",
      "act1 (Activation)            (None, 10, 10, 11, 32)    0         \n",
      "_________________________________________________________________\n",
      "CNN2 (TimeDistributed)       (None, 10, 10, 11, 64)    18496     \n",
      "_________________________________________________________________\n",
      "batch2 (BatchNormalization)  (None, 10, 10, 11, 64)    256       \n",
      "_________________________________________________________________\n",
      "act2 (Activation)            (None, 10, 10, 11, 64)    0         \n",
      "_________________________________________________________________\n",
      "CNN3 (TimeDistributed)       (None, 10, 10, 11, 128)   73856     \n",
      "_________________________________________________________________\n",
      "batch3 (BatchNormalization)  (None, 10, 10, 11, 128)   512       \n",
      "_________________________________________________________________\n",
      "act3 (Activation)            (None, 10, 10, 11, 128)   0         \n",
      "_________________________________________________________________\n",
      "flatten (TimeDistributed)    (None, 10, 14080)         0         \n",
      "_________________________________________________________________\n",
      "FC (Dense)                   (None, 10, 1024)          14418944  \n",
      "_________________________________________________________________\n",
      "dropout1 (Dropout)           (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "batch4 (BatchNormalization)  (None, 10, 1024)          4096      \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 10, 1024)          0         \n",
      "_________________________________________________________________\n",
      "LSTM1 (LSTM)                 (None, 10, 64)            278784    \n",
      "_________________________________________________________________\n",
      "LSTM2 (LSTM)                 (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "FC2 (Dense)                  (None, 1024)              66560     \n",
      "_________________________________________________________________\n",
      "dropout2 (Dropout)           (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 5)                 5125      \n",
      "=================================================================\n",
      "Total params: 14,900,101\n",
      "Trainable params: 14,897,605\n",
      "Non-trainable params: 2,496\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Complicated Model - the same as Zhang`s\n",
    "input_shape = (10, 10, 11, 1)\n",
    "lecun = initializers.lecun_normal(seed=42)\n",
    "\n",
    "# TimeDistributed Wrapper\n",
    "def timeDist(layer, prev_layer, name):\n",
    "    return layers.TimeDistributed(layer, name=name)(prev_layer)\n",
    "    \n",
    "\n",
    "# Input layer\n",
    "inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "# Convolutional layers block\n",
    "x = timeDist(Conv2D(32, (3,3), padding='same', \n",
    "                    data_format='channels_last', kernel_initializer=lecun), inputs, name='CNN1')\n",
    "x = BatchNormalization(name='batch1')(x)\n",
    "x = Activation('elu', name='act1')(x)\n",
    "x = timeDist(Conv2D(64, (3,3), padding='same', data_format='channels_last', kernel_initializer=lecun), x, name='CNN2')\n",
    "x = BatchNormalization(name='batch2')(x)\n",
    "x = Activation('elu', name='act2')(x)\n",
    "x = timeDist(Conv2D(128, (3,3), padding='same', data_format='channels_last', kernel_initializer=lecun), x, name='CNN3')\n",
    "x = BatchNormalization(name='batch3')(x)\n",
    "x = Activation('elu', name='act3')(x)\n",
    "x = timeDist(Flatten(), x, name='flatten')\n",
    "\n",
    "# Fully connected layer block\n",
    "y = Dense(1024, kernel_initializer=lecun, name='FC')(x)\n",
    "y = Dropout(0.5, name='dropout1')(y)\n",
    "y = BatchNormalization(name='batch4')(y)\n",
    "y = Activation(activation='elu')(y)\n",
    "\n",
    "# Recurrent layers block\n",
    "z = LSTM(64, kernel_initializer=lecun, return_sequences=True, name='LSTM1')(y)\n",
    "z = LSTM(64, kernel_initializer=lecun, name='LSTM2')(z)\n",
    "\n",
    "# Fully connected layer block\n",
    "h = Dense(1024, kernel_initializer=lecun, activation='elu', name='FC2')(z)\n",
    "h = Dropout(0.5, name='dropout2')(h)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(5, activation='softmax')(h)\n",
    "\n",
    "# Model compile\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load a model to transfer pre-trained parameters\n",
    "trans_model = model.load('CNN_3blocks.h5')\n",
    "\n",
    "# Transfer learning - parameter copy & paste\n",
    "which_layer = 'CNN1,CNN2,CNN3,batch1,batch2,batch3'.split(',')\n",
    "layer_names = [layer.name for layer in model.layers]\n",
    "trans_layer_names = [layer.name for layer in tran_model.layers]\n",
    "\n",
    "for layer in which_layer:\n",
    "    ind = layer_names.index(layer)\n",
    "    trans_ind = trans_layer_names.index(layer)\n",
    "    model.layers[ind].set_weights(trans_model.layers[trans_ind].get_weights())\n",
    "    \n",
    "for layer in model.layers[:9]: # Freeze the first 9 layers(CNN block)\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn on multi-GPU mode\n",
    "model = multi_gpu_model(model, gpus=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks_list = [callbacks.ModelCheckpoint('model.h5', save_best_only=True, monitor='val_loss'),\n",
    "                 callbacks.EarlyStopping(monitor='acc', patience=3),\n",
    "                 callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=5),\n",
    "                 callbacks.TensorBoard(log_dir='./my_log_dir/', histogram=1)]\n",
    "\n",
    "# Start training\n",
    "model.compile(loss='categorical_crossentropy', optimizer=ptimizers.adam(lr=0.001), metrics=['acc'])\n",
    "model.fit(X_train, y_train, batch_size=64, epochs=5000, validation_data=(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
