{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EEG Classification - Tensorflow\n",
    "updated: Aug. 01, 2018\n",
    "\n",
    "Data: https://www.physionet.org/pn4/eegmmidb/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Downloads\n",
    "\n",
    "### Warning: Executing these blocks will automatically create directories and download datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import requests\n",
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import urllib\n",
    "\n",
    "# Modeling & Preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "\n",
    "# Essential Data Handling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Get Paths\n",
    "from glob import glob\n",
    "\n",
    "# EEG package\n",
    "from mne import find_events, Epochs, concatenate_raws, pick_types\n",
    "from mne.channels import read_montage\n",
    "from mne.io import read_raw_edf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jimmy/anaconda3/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: compiletime version 3.5 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.6\n",
      "  return f(*args, **kwds)\n",
      "/Users/jimmy/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tfe = tf.contrib.eager\n",
    "tf.enable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = 'pn4/'\n",
    "MATERIAL = 'eegmmidb/'\n",
    "URL = 'https://www.physionet.org/' + CONTEXT + MATERIAL\n",
    "\n",
    "# Change this directory according to your setting\n",
    "USERDIR = './data/'\n",
    "\n",
    "page = requests.get(URL).text\n",
    "FOLDERS = sorted(list(set(re.findall(r'S[0-9]+', page))))\n",
    "\n",
    "URLS = [URL+x+'/' for x in FOLDERS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Executing this block will create folders\n",
    "for folder in FOLDERS:\n",
    "    pathlib.Path(USERDIR +'/'+ folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warning: Executing this block will start downloading data\n",
    "for i, folder in enumerate(FOLDERS):\n",
    "    page = requests.get(URLS[i]).text\n",
    "    subs = list(set(re.findall(r'S[0-9]+R[0-9]+', page)))\n",
    "    \n",
    "    print('Working on {}, {:.1%} completed'.format(folder, (i+1)/len(FOLDERS)))\n",
    "    for sub in subs:\n",
    "        urllib.request.urlretrieve(URLS[i]+sub+'.edf', os.path.join(USERDIR, folder, sub+'.edf'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "\n",
    "Subjects performed different motor/imagery tasks while 64-channel EEG were recorded using the BCI2000 system (http://www.bci2000.org). Each subject performed 14 experimental runs: two one-minute baseline runs (one with eyes open, one with eyes closed), and three two-minute runs of each of the four following tasks:\n",
    "A target appears on either the left or the right side of the screen. The subject opens and closes the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "A target appears on either the left or the right side of the screen. The subject imagines opening and closing the corresponding fist until the target disappears. Then the subject relaxes.\n",
    "A target appears on either the top or the bottom of the screen. The subject opens and closes either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "A target appears on either the top or the bottom of the screen. The subject imagines opening and closing either both fists (if the target is on top) or both feet (if the target is on the bottom) until the target disappears. Then the subject relaxes.\n",
    "\n",
    "The data are provided here in EDF+ format (containing 64 EEG signals, each sampled at 160 samples per second, and an annotation channel). For use with PhysioToolkit software, rdedfann generated a separate PhysioBank-compatible annotation file (with the suffix .event) for each recording. The .event files and the annotation channels in the corresponding .edf files contain identical data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Raw Data Import\n",
    "\n",
    "I will use a EEG data handling package named MNE (https://martinos.org/mne/stable/index.html) to import raw data and annotation for events from edf files. This package also provides essential signal analysis features, e.g. band-pass filtering. The raw data were filtered using 1Hz of high-pass filter.\n",
    "\n",
    "In this research, there are 5 classes for the data: imagined motion of right fist, left fist, both fists, both feet, and rest with eyes closed. A data from one of the 109 subjects was excluded as the record was severely corrupted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths\n",
    "PATH = '/Users/jimmy/data/PhysioNet/'\n",
    "SUBS = glob(PATH + 'S[0-9]*')\n",
    "FNAMES = sorted([x[-4:] for x in SUBS])\n",
    "\n",
    "# Remove subject #89 with damaged data\n",
    "FNAMES.remove('S089')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subj_num=FNAMES, epoch_sec=0.0625):\n",
    "    \"\"\" Import from edf files data and targets in the shape of 3D tensor\n",
    "    \n",
    "        Output shape: (Trial*Channel*TimeFrames)\n",
    "        \n",
    "        Some edf+ files recorded at low sampling rate, 128Hz, are excluded. \n",
    "        Majority was sampled at 160Hz.\n",
    "        \n",
    "        epoch_sec: time interval for one segment of mashes\n",
    "        \"\"\"\n",
    "    \n",
    "    # Event codes mean different actions for two groups of runs\n",
    "    run_type_0 = '02'.split(',')\n",
    "    run_type_1 = '04,08,12'.split(',')\n",
    "    run_type_2 = '06,10,14'.split(',')\n",
    "\n",
    "    # To calculated completion rate\n",
    "    count = 0\n",
    "    \n",
    "    # Initiate X, y\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # fixed numbers\n",
    "    nChan = 64 \n",
    "    sfreq = 160\n",
    "    sliding = epoch_sec/2 \n",
    "    \n",
    "    # Sub-function to assign X and X, y\n",
    "    def append_X(n_segments, old_x):\n",
    "        '''This function generate a tensor for X and append it to the existing X'''\n",
    "        new_x = old_x + [data[:, int(sfreq*sliding*n):int(sfreq*sliding*(n+2))] for n in range(n_segments)\\\n",
    "                     if data[:, int(sfreq*sliding*n):int(sfreq*sliding*(n+2))].shape==(nChan, int(sfreq*epoch_sec))]\n",
    "        return new_x\n",
    "    \n",
    "    def append_X_Y(run_type, event, old_x, old_y):\n",
    "        '''This function seperate the type of events \n",
    "        (refer to the data descriptitons for the list of the types)\n",
    "        Then assign X and Y according to the event types'''\n",
    "        # Number of sliding windows\n",
    "        n_segments = int(event[1]/epoch_sec)*2-1\n",
    "        \n",
    "        # Instantiate new_x, new_y\n",
    "        new_y = old_y\n",
    "        new_x = old_x\n",
    "        \n",
    "        # y assignment\n",
    "        if run_type == 1:\n",
    "            if event[2] == 'T1':\n",
    "                new_y = old_y + [1]*n_segments\n",
    "                new_x = append_X(n_segments, old_x)\n",
    "\n",
    "            elif event[2] == 'T2':\n",
    "                new_y = old_y + [2]*n_segments\n",
    "                new_x = append_X(n_segments, old_x)\n",
    "        \n",
    "        if run_type == 2:\n",
    "            if event[2] == 'T1':\n",
    "                new_y = old_y + [3]*n_segments\n",
    "                new_x = append_X(n_segments, old_x)\n",
    "            \n",
    "            elif event[2] == 'T2':\n",
    "                new_y = old_y + [4]*n_segments\n",
    "                new_x = append_X(n_segments, old_x)\n",
    "        \n",
    "        return new_x, new_y\n",
    "    \n",
    "    # Iterate over subj_num: S001, S002, S003...\n",
    "    for subj in subj_num:\n",
    "        # Return completion rate\n",
    "        count+=1\n",
    "        if len(subj_num)//count == 10:\n",
    "            print('working on {}, {:.1%} completed'.format(subj, count/len(subj_num)))\n",
    "\n",
    "        # Get file names\n",
    "        fnames = glob(os.path.join(PATH, subj, subj+'R*.edf'))\n",
    "        fnames = [name for name in fnames if name[-6:-4] in run_type_0+run_type_1+run_type_2]\n",
    "        \n",
    "        for i, fname in enumerate(fnames):\n",
    "            \n",
    "            # Import data into MNE raw object\n",
    "            raw = read_raw_edf(fname, preload=True, verbose=False)\n",
    "            picks = pick_types(raw.info, eeg=True)\n",
    "            \n",
    "            if raw.info['sfreq'] != 160:\n",
    "                print(f'{subj} is sampled at 128Hz so will be excluded.')\n",
    "                break\n",
    "            \n",
    "            # High-pass filtering\n",
    "            raw.filter(l_freq=1, h_freq=None, picks=picks)\n",
    "            \n",
    "            # Get annotation\n",
    "            events = raw.find_edf_events()\n",
    "            \n",
    "            # Get data\n",
    "            data = raw.get_data(picks=picks)\n",
    "            \n",
    "            # Number of this run\n",
    "            which_run = fname[-6:-4]\n",
    "            \n",
    "            \"\"\" Assignment Starts \"\"\" \n",
    "            # run 1 - baseline (eye closed)\n",
    "            if which_run in run_type_0:\n",
    "\n",
    "                # Number of sliding windows\n",
    "                n_segments = int((raw.n_times/(epoch_sec*sfreq))*2-1)\n",
    "                \n",
    "                # Append 0`s based on number of windows\n",
    "                y.extend([0]*n_segments)\n",
    "                X = append_X(n_segments, X)\n",
    "                    \n",
    "            # run 4,8,12 - imagine opening and closing left or right fist    \n",
    "            elif which_run in run_type_1:\n",
    "                \n",
    "                for i, event in enumerate(events):\n",
    "                    X, y = append_X_Y(run_type=1, event=event, old_x=X, old_y=y)\n",
    "                        \n",
    "            # run 6,10,14 - imagine opening and closing both fists or both feet\n",
    "            elif which_run in run_type_2:\n",
    "                   \n",
    "                for i, event in enumerate(events):         \n",
    "                    X, y = append_X_Y(run_type=2, event=event, old_x=X, old_y=y)\n",
    "                        \n",
    "    X = np.stack(X)\n",
    "    y = np.array(y).reshape((-1,1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\" \\nThis code is to test MNE raw object\\n\\nsubj = FNAMES[0]\\nfnames = glob(os.path.join(PATH, subj, subj+'R*'+'.edf'))\\nraw = read_raw_edf(fnames[5], preload=True, verbose=False)\\n\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' \n",
    "This code is to test MNE raw object\n",
    "\n",
    "subj = FNAMES[0]\n",
    "fnames = glob(os.path.join(PATH, subj, subj+'R*'+'.edf'))\n",
    "raw = read_raw_edf(fnames[5], preload=True, verbose=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X,y = get_data(FNAMES[:2], epoch_sec=0.0625)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27122, 64, 10)\n",
      "(27122, 1)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing\n",
    "\n",
    "The original goal of applying neural networks is to exclude hand-crafted algorithms & preprocessing as much as possible. I did not use any proprecessing techniques further than standardization to build an end-to-end classifer from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0% done\n",
      "10% done\n",
      "20% done\n",
      "30% done\n",
      "40% done\n",
      "50% done\n",
      "60% done\n",
      "70% done\n",
      "80% done\n",
      "90% done\n",
      "100% done\n",
      "0% done\n",
      "10% done\n",
      "20% done\n",
      "30% done\n",
      "40% done\n",
      "50% done\n",
      "60% done\n",
      "70% done\n",
      "80% done\n",
      "90% done\n",
      "100% done\n"
     ]
    }
   ],
   "source": [
    "# y encoding\n",
    "oh = OneHotEncoder()\n",
    "y = oh.fit_transform(y).toarray()\n",
    "\n",
    "# Shuffle trials\n",
    "np.random.seed(43)\n",
    "trials = X.shape[0]\n",
    "shuffle_indices = np.random.permutation(trials)\n",
    "X = X[shuffle_indices]\n",
    "y = y[shuffle_indices]\n",
    "\n",
    "# Test set seperation\n",
    "test_ratio = 0.2\n",
    "train_size = int(trials*(1-test_ratio))\n",
    "X_train, X_test, y_train, y_test = X[:train_size,:,:], X[train_size:,:,:],\\\n",
    "                                    y[:train_size,:], y[train_size:,:]\n",
    "    \n",
    "# Z-score Normalization\n",
    "def scale_data(X):\n",
    "    shape = X.shape\n",
    "    scaler = StandardScaler()\n",
    "    scaled_X = np.zeros((shape[0], shape[1], shape[2]))\n",
    "    for i in range(shape[0]):\n",
    "        for z in range(shape[2]):\n",
    "            scaled_X[i, :, z] = np.squeeze(scaler.fit_transform(X[i, :, z].reshape(-1, 1)))\n",
    "        if i%int(shape[0]/10) == 0:\n",
    "            print('{:.0%} done'.format((i+1)/shape[0]))   \n",
    "    return scaled_X\n",
    "            \n",
    "X_train, X_test  = scale_data(X_train), scale_data(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As the EEG recording instrument has 3D locations over the subjects\\` scalp, it is essential for the model to learn from the spatial pattern as well as the temporal pattern. I transformed the data into 2D meshes that represents the locations of the electrodes so that stacked convolutional neural networks can grasp the spatial information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Af3': 25,\n",
       " 'Af4': 27,\n",
       " 'Af7': 24,\n",
       " 'Af8': 28,\n",
       " 'Afz': 26,\n",
       " 'C1': 9,\n",
       " 'C2': 11,\n",
       " 'C3': 8,\n",
       " 'C4': 12,\n",
       " 'C5': 7,\n",
       " 'C6': 13,\n",
       " 'Cp1': 16,\n",
       " 'Cp2': 18,\n",
       " 'Cp3': 15,\n",
       " 'Cp4': 19,\n",
       " 'Cp5': 14,\n",
       " 'Cp6': 20,\n",
       " 'Cpz': 17,\n",
       " 'Cz': 10,\n",
       " 'F1': 32,\n",
       " 'F2': 34,\n",
       " 'F3': 31,\n",
       " 'F4': 35,\n",
       " 'F5': 30,\n",
       " 'F6': 36,\n",
       " 'F7': 29,\n",
       " 'F8': 37,\n",
       " 'Fc1': 2,\n",
       " 'Fc2': 4,\n",
       " 'Fc3': 1,\n",
       " 'Fc4': 5,\n",
       " 'Fc5': 0,\n",
       " 'Fc6': 6,\n",
       " 'Fcz': 3,\n",
       " 'Fp1': 21,\n",
       " 'Fp2': 23,\n",
       " 'Fpz': 22,\n",
       " 'Ft7': 38,\n",
       " 'Ft8': 39,\n",
       " 'Fz': 33,\n",
       " 'Iz': 63,\n",
       " 'O1': 60,\n",
       " 'O2': 62,\n",
       " 'Oz': 61,\n",
       " 'P1': 49,\n",
       " 'P2': 51,\n",
       " 'P3': 48,\n",
       " 'P4': 52,\n",
       " 'P5': 47,\n",
       " 'P6': 53,\n",
       " 'P7': 46,\n",
       " 'P8': 54,\n",
       " 'Po3': 56,\n",
       " 'Po4': 58,\n",
       " 'Po7': 55,\n",
       " 'Po8': 59,\n",
       " 'Poz': 57,\n",
       " 'Pz': 50,\n",
       " 'T10': 43,\n",
       " 'T7': 40,\n",
       " 'T8': 41,\n",
       " 'T9': 42,\n",
       " 'Tp7': 44,\n",
       " 'Tp8': 45}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make 2D meshes\n",
    "# Import one raw EEG data to get electrode locations\n",
    "subj = FNAMES[0]\n",
    "fnames = glob(os.path.join(PATH, subj, subj+'R*'+'.edf'))\n",
    "raw = read_raw_edf(fnames[3], preload=True, verbose=False)\n",
    "ch_names = raw.info['ch_names'][:-1]\n",
    "\n",
    "# 'ch_index' is a dictionary - keys: electrodes, vals: column index of electrodes\n",
    "ch_index = {re.findall(\"\\w+[0-9]?\", i)[0]:ch_names.index(i) for i in ch_names}; ch_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_mesh(X, ch_index=ch_index):\n",
    "    '''\n",
    "    To represent the spatial pattern of the EEG data, \n",
    "    Zhang converts 1D tensors into 2D meshes then applies\n",
    "    2D convolutional layers. This will enable the model \n",
    "    to learn both of the temporal and spatial pattern with\n",
    "    stacked CNN + RNN architectures.\n",
    "    \n",
    "    Output shape = (Samples, Time stamp, Width, Height)\n",
    "    '''\n",
    "    mesh = np.zeros((X.shape[0], X.shape[2], 10, 11))\n",
    "    X = np.swapaxes(X, 1, 2)\n",
    "    \n",
    "    # 1st line\n",
    "    mesh[:, :, 0, 4:7] = X[:,:,21:24]; print('1st finished')\n",
    "    \n",
    "    # 2nd line\n",
    "    mesh[:, :, 1, 3:8] = X[:,:,24:29]; print('2nd finished')\n",
    "    \n",
    "    # 3rd line\n",
    "    mesh[:, :, 2, 1:10] = X[:,:,29:38]; print('3rd finished')\n",
    "    \n",
    "    # 4th line\n",
    "    mesh[:, :, 3, 1:10] = np.concatenate((X[:,:,ch_index['Ft7']].reshape(-1, X.shape[1], 1),\\\n",
    "                                          X[:,:,0:7], X[:,:,ch_index['Ft8']].reshape(-1, X.shape[1], 1)), axis=2)\n",
    "    print('4th finished')\n",
    "    \n",
    "    # 5th line\n",
    "    mesh[:, :, 4, 0:11] = np.concatenate((X[:,:,(ch_index['T9'],ch_index['T7'])],\\\n",
    "                                        X[:,:,7:14], X[:,:,(ch_index['T8'],ch_index['T10'])]), axis=2)\n",
    "    print('5th finished')\n",
    "    \n",
    "    # 6th line\n",
    "    mesh[:, :, 5, 1:10] = np.concatenate((X[:,:,ch_index['Tp7']].reshape(-1, X.shape[1], 1),\\\n",
    "                                        X[:,:,14:21], X[:,:,ch_index['Tp8']].reshape(-1, X.shape[1], 1)), axis=2)\n",
    "    print('6th finished')\n",
    "               \n",
    "    # 7th line\n",
    "    mesh[:, :, 6, 1:10] = X[:,:,46:55]; print('7th finished')\n",
    "    \n",
    "    # 8th line\n",
    "    mesh[:, :, 7, 3:8] = X[:,:,55:60]; print('8th finished')\n",
    "    \n",
    "    # 9th line\n",
    "    mesh[:, :, 8, 4:7] = X[:,:,60:63]; print('9th finished')\n",
    "    \n",
    "    # 10th line\n",
    "    mesh[:, :, 9, 5] = X[:,:,63]; print('10th finished')\n",
    "    \n",
    "    return mesh.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st finished\n",
      "2nd finished\n",
      "3rd finished\n",
      "4th finished\n",
      "5th finished\n",
      "6th finished\n",
      "7th finished\n",
      "8th finished\n",
      "9th finished\n",
      "10th finished\n",
      "1st finished\n",
      "2nd finished\n",
      "3rd finished\n",
      "4th finished\n",
      "5th finished\n",
      "6th finished\n",
      "7th finished\n",
      "8th finished\n",
      "9th finished\n",
      "10th finished\n"
     ]
    }
   ],
   "source": [
    "# Make meshes - Dimension: (Sample * Channel * Width * Height)\n",
    "X_train, X_test = convert_mesh(X_train), convert_mesh(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.  ,  0.  ,  0.  ,  0.  ,  0.43,  0.57,  0.76,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.3 ,  0.47,  1.51,  1.2 ,  1.06,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  , -0.12,  0.08,  1.3 ,  1.55,  1.92,  1.74,  1.62,  0.77, -0.43,  0.  ],\n",
       "       [ 0.  , -0.45, -0.43,  0.75,  1.34,  1.52,  1.45,  1.25,  1.04, -0.3 ,  0.  ],\n",
       "       [-1.13, -0.42, -0.49, -0.  ,  0.38,  0.4 ,  1.11,  0.91,  0.8 ,  0.15, -0.88],\n",
       "       [ 0.  , -0.77, -0.83, -0.43, -0.47,  0.07,  0.36,  0.53,  0.25, -0.79,  0.  ],\n",
       "       [ 0.  , -1.04, -1.07, -1.03, -0.78, -0.62, -0.38, -0.34, -0.62, -0.88,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  , -1.75, -1.45, -0.95, -1.12, -1.53,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  , -1.75, -1.5 , -0.88,  0.  ,  0.  ,  0.  ,  0.  ],\n",
       "       [ 0.  ,  0.  ,  0.  ,  0.  ,  0.  , -1.96,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check out the shape of the mesh\n",
    "np.set_printoptions(precision=2, linewidth=100)\n",
    "X_train[1][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modeling - Time-Distributed CNN + RNN\n",
    "\n",
    "Training Plan:\n",
    "\n",
    "+ 4 GPU units (Nvidia Tesla P100) were used to train this neural network.\n",
    "+ Instead of training the whole model at once, I trained the first block (CNN) first. Then using the trained parameters as initial values, I trained the next blocks step-by-step. This approach can greatly reduce the time required for training and help avoiding falling into local minimums.\n",
    "+ The first blocks (CNN) can be applied for other EEG classification models as a pre-trained base.\n",
    "\n",
    "+ The initial learning rate is set to be $10^{3}$ with Adam optimization. I used several callbacks such as ReduceLROnPlateau which adjusts the learning rate at local minima. Also, I record the log for tensorboard to monitor the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make another dimension, 1, to apply CNN for each time frame.\n",
    "X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3], 1)\n",
    "X_test = X_test.reshape(X_test.shape[0], X_train.shape[1], X_train.shape[2], X_train.shape[3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "num_steps = 3\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "\n",
    "# Network Parameters\n",
    "num_input = X.shape[0] # PhysioNet data input (mesh shape: 10*11)\n",
    "num_classes = 5 # PhysioNet total classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using TF Dataset to split data into batches\n",
    "dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train)).batch(batch_size)\n",
    "dataset_iter = tfe.Iterator(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZhangModel(tf.keras.Model):\n",
    "    def __init__(self, n_nodes=[3,2,2], \n",
    "                 initializer=tf.contrib.layers.variance_scaling_initializer(mode=\"FAN_AVG\")):\n",
    "        \"\"\"\n",
    "        This is a tensorflow implementation of Zhang`s model (2018) with \n",
    "        3 CNN, 2 LSTM, 2 dense layers.\n",
    "        \n",
    "        n_nodes [list] : specifies the number of layers for each block. \n",
    "                        [CNN, LSTM, DENSE] respectively.\n",
    "        initializer [tf.layers] : defualt initializer set to be He initializer\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.n_CNN, self.n_LSTM, self.n_dense = n_nodes\n",
    "        self.CNN, self.LSTM, self.dense = [[] for i in range(len(n_nodes))]\n",
    "        self.initializer = initializer\n",
    "        \n",
    "        count = 0\n",
    "        for n in range(self.n_CNN):\n",
    "            count += 1\n",
    "            n_filter = 32*2**count\n",
    "            \n",
    "            self.CNN.append(tf.keras.layers.Conv2D(n_filter, (3, 3), padding='same', \n",
    "                                                data_format='channels_last',\n",
    "                                                kernel_initializer=self.initializer))\n",
    "        \n",
    "        for n in range(self.n_LSTM):    \n",
    "            n_hidden = 64\n",
    "            return_sequences = False if n == self.n_LSTM-1 else True\n",
    "            \n",
    "            name = 'LSTM' + str(len(self.LSTM)+1)            \n",
    "            self.LSTM.append(tf.keras.layers.LSTM(n_hidden, kernel_initializer=self.initializer, \n",
    "                                             return_sequences=return_sequences, name=name))\n",
    "            \n",
    "        for n in range(self.n_dense):\n",
    "            n_node=1024\n",
    "            \n",
    "            name = 'Dense' + str(len(self.dense)+1)\n",
    "            self.dense.append(tf.keras.layers.Dense(n_node, \n",
    "                                                    kernel_initializer=self.initializer, name=name))\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        \"Run the model.\"\n",
    "        \n",
    "        assert self.CNN, 'No CNN blocks defined!'\n",
    "        assert self.dense, 'No Dense Blocks defined!'\n",
    "        assert self.LSTM, 'No LSTM blocks defined!'\n",
    "        \n",
    "        def timeDist(layer, prev_layer, name):\n",
    "            return tf.keras.layers.TimeDistributed(layer, name=name)(prev_layer)\n",
    "        \n",
    "        for i, layer in enumerate(self.CNN):\n",
    "            name = 'CNN' + str(i+1)\n",
    "            nameBatch = 'batch' + str(i+1)\n",
    "            nameAct = 'act' + str(i+1)\n",
    "            \n",
    "            prev_layer = input_tensor if i==0 else x\n",
    "            \n",
    "            x = timeDist(layer, prev_layer, name=name)\n",
    "            x = tf.keras.layers.BatchNormalization(name=nameBatch)(x)\n",
    "            x = tf.nn.elu(x, name=nameAct)\n",
    "            \n",
    "        x = timeDist(tf.keras.layers.Flatten(), x, name='flatten')\n",
    "        \n",
    "        for i, layer in enumerate(self.dense):            \n",
    "            \n",
    "            nameDrop = 'drop' + str(i+1)\n",
    "            nameBatch = 'batch' + str(i+1)\n",
    "            nameAct = 'act' + str(i+1)\n",
    "            \n",
    "            if i == len(self.dense)-1:\n",
    "                break\n",
    "            \n",
    "            x = layer(x)\n",
    "            x = tf.keras.layers.Dropout(0.5, name=nameDrop)(x)\n",
    "            x = tf.keras.layers.BatchNormalization(name=nameBatch)(x)\n",
    "            x = tf.nn.elu(x, name=nameAct)\n",
    "            \n",
    "        for i, layer in enumerate(self.LSTM):\n",
    "            x = layer(x)\n",
    "        \n",
    "        x = self.dense[-1](x)\n",
    "        x = tf.keras.layers.Dropout(0.5, name=nameDrop)(x)\n",
    "        x = tf.keras.layers.BatchNormalization(name=nameBatch)(x)\n",
    "        x = tf.nn.elu(x, name=nameAct)\n",
    "        \n",
    "        output = tf.keras.layers.Dense(5, activation='softmax')(x)\n",
    "        \n",
    "        return output    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[0.2  0.19 0.21 0.21 0.19]], shape=(1, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "model = ZhangModel([3, 2, 2])\n",
    "print(model(tf.random_normal([1, 10, 10, 11, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-Entropy loss function\n",
    "def loss_fn(inference_fn, inputs, labels):\n",
    "    # Using sparse_softmax cross entropy\n",
    "    return tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(\n",
    "        logits=inference_fn(inputs), labels=labels))\n",
    "\n",
    "\n",
    "# Calculate accuracy\n",
    "def accuracy_fn(inference_fn, inputs, labels):\n",
    "    prediction = inference_fn(inputs)\n",
    "    correct_pred = tf.equal(tf.argmax(prediction, 1), tf.argmax(labels, 1))\n",
    "    return tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
    "\n",
    "# SGD Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "# Compute gradients\n",
    "grad = tfe.implicit_gradients(loss_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial loss= 1.612895250\n",
      "Step: 0001  loss= 1.612895250  accuracy= 0.2031\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "average_loss = 0.\n",
    "average_acc = 0.\n",
    "for step in range(num_steps):\n",
    "\n",
    "    # Iterate through the dataset\n",
    "    try:\n",
    "        d = dataset_iter.next()\n",
    "    except StopIteration:\n",
    "        # Refill queue\n",
    "        dataset_iter = tfe.Iterator(dataset)\n",
    "        d = dataset_iter.next()\n",
    "\n",
    "    # EEGs\n",
    "    x_batch = d[0]\n",
    "    # Labels\n",
    "    y_batch = tf.cast(d[1], dtype=tf.int64)\n",
    "\n",
    "    # Compute the batch loss\n",
    "    batch_loss = loss_fn(model, x_batch, y_batch)\n",
    "    average_loss += batch_loss\n",
    "    \n",
    "    # Compute the batch accuracy\n",
    "    batch_accuracy = accuracy_fn(model, x_batch, y_batch)\n",
    "    average_acc += batch_accuracy\n",
    "\n",
    "    if step == 0:\n",
    "        # Display the initial cost, before optimizing\n",
    "        print(\"Initial loss= {:.9f}\".format(average_loss))\n",
    "\n",
    "    # Update the variables following gradients info\n",
    "    optimizer.apply_gradients(grad(model, x_batch, y_batch))\n",
    "\n",
    "    # Display info\n",
    "    if (step + 1) % display_step == 0 or step == 0:\n",
    "        if step > 0:\n",
    "            average_loss /= display_step\n",
    "            average_acc /= display_step\n",
    "        print(\"Step:\", '%04d' % (step + 1), \" loss=\",\n",
    "              \"{:.9f}\".format(average_loss), \" accuracy=\",\n",
    "              \"{:.4f}\".format(average_acc))\n",
    "        average_loss = 0.\n",
    "        average_acc = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
