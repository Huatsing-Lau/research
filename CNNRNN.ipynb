{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Downloads\n",
    "\n",
    "### Warning: Executing these blocks will automatically create directories and download datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import pathlib\n",
    "import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CONTEXT = 'pn4/'\n",
    "MATERIAL = 'eegmmidb/'\n",
    "URL = 'https://www.physionet.org/' + CONTEXT + MATERIAL\n",
    "\n",
    "USERDIR = '/Users/Jimmy/data/PhysioNet/'\n",
    "\n",
    "page = requests.get(URL).text\n",
    "FOLDERS = sorted(list(set(re.findall(r'S[0-9]+', page))))\n",
    "\n",
    "URLS = [URL+x+'/' for x in FOLDERS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for folder in FOLDERS:\n",
    "#    pathlib.Path(USERDIR + folder).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on S077, 0.9% completed\n",
      "Working on S078, 1.8% completed\n",
      "Working on S079, 2.8% completed\n",
      "Working on S080, 3.7% completed\n",
      "Working on S081, 4.6% completed\n",
      "Working on S082, 5.5% completed\n",
      "Working on S083, 6.4% completed\n",
      "Working on S084, 7.3% completed\n",
      "Working on S085, 8.3% completed\n",
      "Working on S086, 9.2% completed\n",
      "Working on S087, 10.1% completed\n",
      "Working on S088, 11.0% completed\n",
      "Working on S089, 11.9% completed\n",
      "Working on S090, 12.8% completed\n",
      "Working on S091, 13.8% completed\n",
      "Working on S092, 14.7% completed\n",
      "Working on S093, 15.6% completed\n",
      "Working on S094, 16.5% completed\n",
      "Working on S095, 17.4% completed\n",
      "Working on S096, 18.3% completed\n",
      "Working on S097, 19.3% completed\n",
      "Working on S098, 20.2% completed\n",
      "Working on S099, 21.1% completed\n",
      "Working on S100, 22.0% completed\n",
      "Working on S101, 22.9% completed\n",
      "Working on S102, 23.9% completed\n",
      "Working on S103, 24.8% completed\n",
      "Working on S104, 25.7% completed\n",
      "Working on S105, 26.6% completed\n",
      "Working on S106, 27.5% completed\n",
      "Working on S107, 28.4% completed\n",
      "Working on S108, 29.4% completed\n",
      "Working on S109, 30.3% completed\n"
     ]
    }
   ],
   "source": [
    "for i, folder in enumerate(FOLDERS):\n",
    "    page = requests.get(URLS[i]).text\n",
    "    subs = list(set(re.findall(r'S[0-9]+R[0-9]+', page)))\n",
    "    \n",
    "    print('Working on {}, {:.1%} completed'.format(folder, (i+1)/len(FOLDERS)))\n",
    "    for sub in subs:\n",
    "        urllib.request.urlretrieve(URLS[i]+sub+'.edf', os.path.join(USERDIR, folder, sub+'.edf'))\n",
    "        urllib.request.urlretrieve(URLS[i]+sub+'.edf.event', os.path.join(USERDIR, folder, sub+'.edf.event'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Raw Data Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "    \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from glob import glob\n",
    "\n",
    "from mne import find_events, Epochs, concatenate_raws, pick_types\n",
    "from mne.channels import read_montage\n",
    "from mne.io import read_raw_edf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file paths\n",
    "PATH = '/Users/jimmy/data/PhysioNet/'\n",
    "SUBS = glob(PATH+ 'S[0-9]*')\n",
    "FNAMES = sorted([x[-4:] for x in SUBS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /Users/jimmy/data/PhysioNet/S100/S100R04.edf...\n",
      "EDF file detected\n",
      "EDF annotations detected (consider using raw.find_edf_events() to extract them)\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n",
      "Reading 0 ... 15743  =      0.000 ...   122.992 secs...\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n"
     ]
    }
   ],
   "source": [
    "# Import sample data\n",
    "raw = read_raw_edf(os.path.join('/Users/jimmy/data/PhysioNet/S100', 'S100R04.edf'), preload=True)\n",
    "montage = read_montage('standard_1020')\n",
    "raw.info['montage'] = montage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 15744)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.get_data(picks=picks).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 5.125, 'T0'],\n",
       " [5.125, 5.125, 'T1'],\n",
       " [10.25, 5.125, 'T0'],\n",
       " [15.38, 5.125, 'T2'],\n",
       " [20.5, 5.125, 'T0'],\n",
       " [25.62, 5.125, 'T2'],\n",
       " [30.75, 5.125, 'T0'],\n",
       " [35.88, 5.125, 'T1'],\n",
       " [41.0, 5.125, 'T0'],\n",
       " [46.12, 5.125, 'T1'],\n",
       " [51.25, 5.125, 'T0'],\n",
       " [56.38, 5.125, 'T2'],\n",
       " [61.5, 5.125, 'T0'],\n",
       " [66.62, 5.125, 'T1'],\n",
       " [71.75, 5.125, 'T0'],\n",
       " [76.88, 5.125, 'T2'],\n",
       " [82.0, 5.125, 'T0'],\n",
       " [87.12, 5.125, 'T2'],\n",
       " [92.25, 5.125, 'T0'],\n",
       " [97.38, 5.125, 'T1'],\n",
       " [102.5, 5.125, 'T0'],\n",
       " [107.6, 5.125, 'T2'],\n",
       " [112.8, 5.125, 'T0'],\n",
       " [117.9, 5.125, 'T1']]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw.find_edf_events()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "picks = pick_types(raw.info, eeg=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Event codes mean different actions for two groups of runs\n",
    "event_0 = '01,02'.split(',')\n",
    "event_1 = '03,04,07,08,11,12'.split(',')\n",
    "event_2 = '05,06,09,10,13,14'.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(subj_num=FNAMES, resampling=True):\n",
    "    \"\"\"Import each subject`s trials and make a 3D array\n",
    "        The output shape: (Trial*Channel*Frames)\n",
    "        \n",
    "        Set 'resampling=False' to exclude some edf+ files recored\n",
    "        at low sampling rate, 128Hz. Majority was sampled at 160Hz.\"\"\"\n",
    "    # To calculated the completion rate\n",
    "    count=0\n",
    "    \n",
    "    # Initiate X, y\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    for fname in subj_num:\n",
    "        count+=1\n",
    "        print('working on {}, {:.1%} completed'.format(fname, count/len(subj_num)))\n",
    "        \n",
    "        fnames = glob(os.path.join(PATH, fname, fname+'R*'+'.edf'))\n",
    "    \n",
    "\n",
    "        for i, fname in enumerate(fnames):\n",
    "            \n",
    "            # Import data into MNE raw object\n",
    "            raw = read_raw_edf(fname, preload=True, verbose=False)\n",
    "            picks = pick_types(raw.info, eeg=True)\n",
    "            \n",
    "            # Resampling\n",
    "            if resampling:\n",
    "                events = find_events(raw, initial_event=True, verbose=False)\n",
    "                raw, events = raw.copy().resample(128, npad='auto', events=events, verbose=False)\n",
    "                sfreq = 120\n",
    "                \n",
    "            else:\n",
    "                sfreq = 160\n",
    "                if raw.info['sfreq'] != 160:\n",
    "                    print(f'{fname} is sampled at 128Hz so will be excluded.')\n",
    "                    pass\n",
    "            \n",
    "            # High-pass filtering\n",
    "            raw.filter(l_freq=1, h_freq=None, picks=picks)\n",
    "            \n",
    "            # Get annotation\n",
    "            events = raw.find_edf_events()\n",
    "            \n",
    "            # Get data\n",
    "            data = raw.get_data(picks=picks)\n",
    "            \n",
    "            # Epoch period\n",
    "            epoch_sec = 4\n",
    "        \n",
    "            # Experiment number 0,1\n",
    "            if fname[-6:-4] in event_0:\n",
    "                for n in range(15):\n",
    "                    \n",
    "                    X.append(data[:, int(sfreq*epoch_sec*n):int(sfreq*epoch_sec*(n+1))])\n",
    "                    y.append(0)\n",
    "                    \n",
    "                    if X[-1].shape != (64, sfreq*epoch_sec): print(F'shape error!: {fname}, {X[-1].shape}') \n",
    "                    \n",
    "            # Experiment number 3,4,7,8,11,12        \n",
    "            elif fname[-6:-4] in event_1:\n",
    "                for n in range(len(events)):\n",
    "                \n",
    "                    if events[n][2] == 'T0':\n",
    "                        y.append(0)\n",
    "                    elif events[n][2] == 'T1':\n",
    "                        y.append(1)\n",
    "                    else:\n",
    "                        y.append(2)\n",
    "                    \n",
    "                    X.append(data[:, int(events[n][0]*sfreq):int(events[n][0]*sfreq)+sfreq*epoch_sec])\n",
    "                    if X[-1].shape != (64, sfreq*epoch_sec): print(F'shape error!: {fname}, {X[-1].shape}')\n",
    "                        \n",
    "            # Experiment number 5,6,9,10,13,14\n",
    "            else:\n",
    "                for n in range(len(events)):\n",
    "            \n",
    "                    if events[n][2] == 'T0':\n",
    "                        y.append(0)\n",
    "                    elif events[n][2] == 'T1':\n",
    "                        y.append(3)\n",
    "                    else:\n",
    "                        y.append(4)\n",
    "                \n",
    "                    X.append(data[:, int(events[n][0]*sfreq):int(events[n][0]*sfreq)+sfreq*epoch_sec])\n",
    "                    if X[-1].shape != (64, sfreq*epoch_sec): print(F'shape error!: {fname}, {X[-1].shape}')\n",
    "                        \n",
    "    X = np.stack(X)\n",
    "    y = np.array(y).reshape((-1,1))\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on S001, 0.9% completed\n",
      "working on S002, 1.8% completed\n",
      "working on S003, 2.8% completed\n",
      "working on S004, 3.7% completed\n",
      "working on S005, 4.6% completed\n",
      "working on S006, 5.5% completed\n",
      "working on S007, 6.4% completed\n",
      "working on S008, 7.3% completed\n",
      "working on S009, 8.3% completed\n",
      "working on S010, 9.2% completed\n",
      "working on S011, 10.1% completed\n",
      "working on S012, 11.0% completed\n",
      "working on S013, 11.9% completed\n",
      "working on S014, 12.8% completed\n",
      "working on S015, 13.8% completed\n",
      "working on S016, 14.7% completed\n",
      "working on S017, 15.6% completed\n",
      "working on S018, 16.5% completed\n",
      "working on S019, 17.4% completed\n",
      "working on S020, 18.3% completed\n",
      "working on S021, 19.3% completed\n",
      "working on S022, 20.2% completed\n",
      "working on S023, 21.1% completed\n",
      "working on S024, 22.0% completed\n",
      "working on S025, 22.9% completed\n",
      "working on S026, 23.9% completed\n",
      "working on S027, 24.8% completed\n",
      "working on S028, 25.7% completed\n",
      "working on S029, 26.6% completed\n",
      "working on S030, 27.5% completed\n",
      "working on S031, 28.4% completed\n",
      "working on S032, 29.4% completed\n",
      "working on S033, 30.3% completed\n",
      "working on S034, 31.2% completed\n",
      "working on S035, 32.1% completed\n",
      "working on S036, 33.0% completed\n",
      "working on S037, 33.9% completed\n",
      "working on S038, 34.9% completed\n",
      "working on S039, 35.8% completed\n",
      "working on S040, 36.7% completed\n",
      "working on S041, 37.6% completed\n",
      "working on S042, 38.5% completed\n",
      "working on S043, 39.4% completed\n",
      "working on S044, 40.4% completed\n",
      "working on S045, 41.3% completed\n",
      "working on S046, 42.2% completed\n",
      "working on S047, 43.1% completed\n",
      "working on S048, 44.0% completed\n",
      "working on S049, 45.0% completed\n",
      "working on S050, 45.9% completed\n",
      "working on S051, 46.8% completed\n",
      "working on S052, 47.7% completed\n",
      "working on S053, 48.6% completed\n",
      "working on S054, 49.5% completed\n",
      "working on S055, 50.5% completed\n",
      "working on S056, 51.4% completed\n",
      "working on S057, 52.3% completed\n",
      "working on S058, 53.2% completed\n",
      "working on S059, 54.1% completed\n",
      "working on S060, 55.0% completed\n",
      "working on S061, 56.0% completed\n",
      "working on S062, 56.9% completed\n",
      "working on S063, 57.8% completed\n",
      "working on S064, 58.7% completed\n",
      "working on S065, 59.6% completed\n",
      "working on S066, 60.6% completed\n",
      "working on S067, 61.5% completed\n",
      "working on S068, 62.4% completed\n",
      "working on S069, 63.3% completed\n",
      "working on S070, 64.2% completed\n",
      "working on S071, 65.1% completed\n",
      "working on S072, 66.1% completed\n",
      "working on S073, 67.0% completed\n",
      "working on S074, 67.9% completed\n",
      "working on S075, 68.8% completed\n",
      "working on S076, 69.7% completed\n",
      "working on S077, 70.6% completed\n",
      "working on S078, 71.6% completed\n",
      "working on S079, 72.5% completed\n",
      "working on S080, 73.4% completed\n",
      "working on S081, 74.3% completed\n",
      "working on S082, 75.2% completed\n",
      "working on S083, 76.1% completed\n",
      "working on S084, 77.1% completed\n",
      "working on S085, 78.0% completed\n",
      "working on S086, 78.9% completed\n",
      "working on S087, 79.8% completed\n",
      "working on S088, 80.7% completed\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "working on S089, 81.7% completed\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "working on S090, 82.6% completed\n",
      "working on S091, 83.5% completed\n",
      "working on S092, 84.4% completed\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "working on S093, 85.3% completed\n",
      "working on S094, 86.2% completed\n",
      "working on S095, 87.2% completed\n",
      "working on S096, 88.1% completed\n",
      "working on S097, 89.0% completed\n",
      "working on S098, 89.9% completed\n",
      "working on S099, 90.8% completed\n",
      "working on S100, 91.7% completed\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "EDF+ with overlapping events are not fully supported\n",
      "working on S101, 92.7% completed\n",
      "working on S102, 93.6% completed\n",
      "working on S103, 94.5% completed\n",
      "working on S104, 95.4% completed\n",
      "working on S105, 96.3% completed\n",
      "working on S106, 97.2% completed\n",
      "working on S107, 98.2% completed\n",
      "working on S108, 99.1% completed\n",
      "working on S109, 100.0% completed\n"
     ]
    }
   ],
   "source": [
    "X,y = get_data(FNAMES, resampling=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42619, 64, 480)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42619, 1)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv1D, Dense, Flatten, MaxPool1D, Activation\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import OneHotEncoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "oh = OneHotEncoder()\n",
    "y = oh.fit_transform(y).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 30, 10)            24010     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 14, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 140)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                9024      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 33,359\n",
      "Trainable params: 33,359\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/1\n",
      "42619/42619 [==============================] - 116s 3ms/step - loss: 1.3382 - acc: 0.5378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1ac85128>"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv1D(filters=10, input_shape=(64,480), kernel_size=5, padding='valid', strides=2, activation='elu'))\n",
    "model.add(MaxPool1D(pool_size=(4), strides=2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='elu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "print(model.summary())\n",
    "model.fit(X,y, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 64, 128)           61568     \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 64)                524352    \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 586,245\n",
      "Trainable params: 586,245\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(128, input_shape=(64,480), activation='elu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='elu'))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "42619/42619 [==============================] - 122s 3ms/step - loss: 1.3383 - acc: 0.5380\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1c1b7bc240>"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=64, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
